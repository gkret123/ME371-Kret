{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 - - NUMPY and PANDAS FOR DATA ANALYSIS\n",
    "# Gabriel Kret\n",
    "# Due: 10/21/2024\n",
    "\n",
    "#This exercise is about using numpy and pandas to analyze data.\n",
    "\n",
    "#Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[( 1, 'Water', 5.2242642e+03, 5.345930e+03, 2.5031309e+03, 2.49     , 1.99 , 1.8665386 , 49.854286, 51.72 , 23.575453 , 1.9514285e+00,  1.56 , 1.4614768e+00)\n",
      " ( 2, 'Air', 7.2733335e+00, 8.050000e+00, 1.6667433e+00, 2.4566667, 1.48 , 2.2130146 , 56.45    , 57.61 ,  5.541814 , 3.3333334e-03,  0.   , 5.7735029e-03)\n",
      " ( 3, 'Oil', 1.8758334e+03, 7.946300e+02, 2.0750293e+03, 3.1733334, 4.3  , 2.2703598 , 45.77667 , 46.17 , 25.462278 , 2.7800000e+00,  3.77 , 1.9892461e+00)\n",
      " ( 6, 'Mercury', 3.0704099e+03, 1.724200e+03, 2.3592539e+03, 3.7733333, 3.49 , 1.0151026 , 75.56333 , 89.12 , 33.34987  , 3.0366666e+00,  2.81 , 8.1402296e-01)\n",
      " ( 7, 'Acetone', 6.0995609e+04, 6.099207e+04, 1.5003267e+04, 2.3575   , 2.79 , 1.157076  , 58.9325  , 53.525, 18.587267 , 3.1934999e+01, 37.79 , 1.5672393e+01)\n",
      " ( 8, 'Benzene', 4.7392998e+03, 4.509840e+03, 1.5979779e+03, 2.745    , 2.455, 1.218043  , 47.13375 , 31.215, 32.145294 , 2.3337500e+00,  2.09 , 1.0354977e+00)\n",
      " ( 9, 'Propylene Glycol', 4.9899565e+03, 4.203800e+03, 2.9196592e+03, 2.4209092, 2.21 , 0.91654193, 70.045456, 74.76 , 19.766262 , 2.4945455e+00,  2.28 , 9.4340199e-01)\n",
      " (10, 'Liquid Nitrogen', 7.6082651e+03, 7.608265e+03, 3.2917588e+03, 2.255    , 2.255, 1.661701  , 98.105   , 98.105,  2.6657925, 2.2550001e+00,  2.255, 1.6617010e+00)]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def calculate_fluid_statistics(root_dir):\n",
    "    \"\"\"\n",
    "    Calculate statistics for fluid experiments from CSV files.\n",
    "\n",
    "    This function loads data from fluids.csv, experiments.csv, and fluid_measurements.csv, merges the data, and calculates mean, median, and standard deviation of pressure, velocity, temperature, and flow_rate for each unique fluid.\n",
    "\n",
    "    Parameters:\n",
    "    root_dir (str): The root directory containing the CSV files.\n",
    "\n",
    "    Returns:\n",
    "    np.array: A structured NumPy array containing the calculated statistics for each fluid.\n",
    "        The array has the following fields:\n",
    "        - fluid_id (int): The unique identifier for each fluid.\n",
    "        - fluid_name (str): The name of the fluid.\n",
    "        - pressure_mean, pressure_median, pressure_std (float): Statistics for pressure.\n",
    "        - velocity_mean, velocity_median, velocity_std (float): Statistics for velocity.\n",
    "        - temperature_mean, temperature_median, temperature_std (float): Statistics for temperature.\n",
    "        - flow_rate_mean, flow_rate_median, flow_rate_std (float): Statistics for flow rate.\n",
    "    \"\"\"\n",
    "    #read data\n",
    "    fluids = pd.read_csv(root_dir + '/fluids.csv')\n",
    "    experiments = pd.read_csv(root_dir + '/experiments.csv')\n",
    "    fluid_measurements = pd.read_csv(root_dir + '/fluid_measurements.csv')\n",
    "    \n",
    "    #merge data\n",
    "    data = pd.merge(fluid_measurements, experiments, on='experiment_id', how='left')\n",
    "    data = pd.merge(data, fluids, on='fluid_id', how = 'left')\n",
    "\n",
    "    #calculate statistics\n",
    "    stats = data.groupby('fluid_name').agg({\n",
    "        'pressure': ['mean', 'median', 'std'],\n",
    "        'velocity': ['mean', 'median', 'std'],\n",
    "        'temperature': ['mean', 'median', 'std'],\n",
    "        'flow_rate': ['mean', 'median', 'std'],\n",
    "    })\n",
    "\n",
    "    #create array\n",
    "    result_array = np.array(np.zeros(len(stats)), dtype=[('fluid_id', 'i4'), ('fluid_name', 'U50'), ('pressure_mean', 'f4'), ('pressure_median', 'f4'), ('pressure_std', 'f4'), ('velocity_mean', 'f4'), ('velocity_median', 'f4'), ('velocity_std', 'f4'), ('temperature_mean', 'f4'), ('temperature_median', 'f4'), ('temperature_std', 'f4'), ('flow_rate_mean', 'f4'), ('flow_rate_median', 'f4'), ('flow_rate_std', 'f4')])\n",
    "    result_array['fluid_id'] = data.groupby('fluid_id')['fluid_id'].first().values\n",
    "    result_array['fluid_name'] = data.groupby('fluid_id')['fluid_name'].first().values\n",
    "    result_array['pressure_mean'] = stats['pressure']['mean'].values\n",
    "    result_array['pressure_median'] = stats['pressure']['median'].values\n",
    "    result_array['pressure_std'] = stats['pressure']['std'].values\n",
    "    result_array['velocity_mean'] = stats['velocity']['mean'].values\n",
    "    result_array['velocity_median'] = stats['velocity']['median'].values\n",
    "    result_array['velocity_std'] = stats['velocity']['std'].values\n",
    "    result_array['temperature_mean'] = stats['temperature']['mean'].values\n",
    "    result_array['temperature_median'] = stats['temperature']['median'].values\n",
    "    result_array['temperature_std'] = stats['temperature']['std'].values\n",
    "    result_array['flow_rate_mean'] = stats['flow_rate']['mean'].values\n",
    "    result_array['flow_rate_median'] = stats['flow_rate']['median'].values\n",
    "    result_array['flow_rate_std'] = stats['flow_rate']['std'].values\n",
    "\n",
    "    print(result_array)\n",
    "      \n",
    "\n",
    "# Call the function and print the results\n",
    "result_array = calculate_fluid_statistics(root_dir='exercise_data') # change root_dir to where your data for this exercise is\n",
    "print(result_array)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment IDs for fluid_id 1:\n",
      "[13  8]\n",
      "\n",
      "Correlation Matrix:\n",
      "             pressure  velocity  temperature  flow_rate\n",
      "pressure          1.0       1.0         -1.0        1.0\n",
      "velocity          1.0       1.0         -1.0        1.0\n",
      "temperature      -1.0      -1.0          1.0       -1.0\n",
      "flow_rate         1.0       1.0         -1.0        1.0\n"
     ]
    }
   ],
   "source": [
    "def get_experiments_and_correlation(root_dir, fluid_id):\n",
    "    \"\"\"\n",
    "    Retrieves experiment IDs for a given fluid and calculates the correlation matrix of measurements.\n",
    "\n",
    "    Parameters:\n",
    "    root_dir (str): The root directory containing the CSV files.\n",
    "    fluid_id (int): The ID of the fluid to analyze.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two elements:\n",
    "        - numpy.ndarray: An array of experiment IDs associated with the given fluid_id.\n",
    "        - pandas.DataFrame: A correlation matrix of pressure, velocity, temperature, and flow_rate for the experiments associated with the given fluid_id.\n",
    "    \"\"\"\n",
    "    #read data\n",
    "    fluids = pd.read_csv(root_dir + '/fluids.csv')\n",
    "    experiments = pd.read_csv(root_dir + '/experiments.csv')\n",
    "    fluid_measurements = pd.read_csv(root_dir + '/fluid_measurements.csv')\n",
    "\n",
    "    #merge data\n",
    "    data = pd.merge(fluid_measurements, experiments, on='experiment_id', how='left')\n",
    "    data = pd.merge(data, fluids, on='fluid_id', how = 'left')\n",
    "\n",
    "    #get experiment ids\n",
    "    experiment_ids = data[data['fluid_id'] == fluid_id]['experiment_id'].values\n",
    "\n",
    "    #calculate correlation matrix\n",
    "    correlation_matrix = data[data['fluid_id'] == fluid_id][['pressure', 'velocity', 'temperature', 'flow_rate']].corr()\n",
    "\n",
    "    return np.array(experiment_ids), correlation_matrix\n",
    "    \n",
    "\n",
    "# Call the function\n",
    "root_dir = 'exercise_data' # change root_dir to where your data for this exercise is\n",
    "fluid_id = 1\n",
    "experiment_ids, correlation_matrix = get_experiments_and_correlation(root_dir, fluid_id)\n",
    "\n",
    "# Print results\n",
    "print(f\"Experiment IDs for fluid_id {fluid_id}:\")\n",
    "print(experiment_ids)\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized 5x3 Fluid Property Matrix:\n",
      "[[7.93449981e-01 6.54607899e-04 1.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.74286509e-01 6.65468030e-03 3.12991507e-01]\n",
      " [6.25826697e-01 7.87942841e-04 4.38817238e-01]\n",
      " [1.00000000e+00 1.00000000e+00 4.38817238e-01]]\n",
      "\n",
      "Normalized Matrix with Column Names:\n",
      "    density  viscosity  specific_heat\n",
      "0  0.793450   0.000655       1.000000\n",
      "1  0.000000   0.000000       0.000000\n",
      "2  0.674287   0.006655       0.312992\n",
      "3  0.625827   0.000788       0.438817\n",
      "4  1.000000   1.000000       0.438817\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_normalized_fluid_matrix(root_dir):\n",
    "    \"\"\"\n",
    "    Create a normalized 5x3 matrix of fluid properties.\n",
    "\n",
    "    This function reads fluid data from a CSV file, selects the first 5 fluids, and creates a matrix of their density, viscosity, and specific heat properties. The matrix is then normalized using min-max normalization.\n",
    "\n",
    "    Parameters:\n",
    "    root_dir (str): The root directory containing the fluids.csv file.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 5x3 normalized matrix where each row represents a fluid and each column represents a normalized property (density, viscosity, specific_heat).\n",
    "    \"\"\"\n",
    "    fluids = pd.read_csv(root_dir + '/fluids.csv')\n",
    "    fluids = fluids[['density', 'viscosity', 'specific_heat']]\n",
    "    fluids = fluids.head(5)\n",
    "    fluids = fluids.to_numpy()\n",
    "\n",
    "    min_values = np.min(fluids, axis=0)\n",
    "    max_values = np.max(fluids, axis=0)\n",
    "\n",
    "    normalized_fluids = (fluids - min_values) / (max_values - min_values)\n",
    "\n",
    "    return normalized_fluids\n",
    "\n",
    "# Call the function\n",
    "root_dir = 'exercise_data' # change root_dir to where your data for this exercise is\n",
    "result_matrix = create_normalized_fluid_matrix(root_dir)\n",
    "\n",
    "# Print the result\n",
    "print(\"Normalized 5x3 Fluid Property Matrix:\")\n",
    "print(result_matrix)\n",
    "\n",
    "# Print with column names for clarity\n",
    "column_names = ['density', 'viscosity', 'specific_heat']\n",
    "result_df = pd.DataFrame(result_matrix, columns=column_names)\n",
    "print(\"\\nNormalized Matrix with Column Names:\")\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized 5x3 Fluid Property Matrix:\n",
      "[[7.93449981e-01 6.54607899e-04 1.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.74286509e-01 6.65468030e-03 3.12991507e-01]\n",
      " [6.25826697e-01 7.87942841e-04 4.38817238e-01]\n",
      " [1.00000000e+00 1.00000000e+00 4.38817238e-01]]\n",
      "\n",
      "Correlation Matrix:\n",
      "[[1.00000000e+00 5.70589790e-01 6.68644167e-01]\n",
      " [5.70589790e-01 1.00000000e+00 3.52574102e-04]\n",
      " [6.68644167e-01 3.52574102e-04 1.00000000e+00]]\n",
      "\n",
      "Eigenvalues:\n",
      "[1.87918363 0.12116456 0.99965181]\n",
      "\n",
      "Eigenvectors:\n",
      "[[ 7.07036753e-01  7.07176800e-01  6.30797704e-05]\n",
      " [ 4.59082256e-01 -4.58923489e-01 -7.60679114e-01]\n",
      " [ 5.37905672e-01 -5.37857049e-01  6.49128094e-01]]\n",
      "\n",
      "Explained Variance Ratio:\n",
      "Principal Component 1: 0.6264\n",
      "Principal Component 2: 0.0404\n",
      "Principal Component 3: 0.3332\n",
      "\n",
      "The property that contributes most to the first principal component is: density\n",
      "Its contribution is: 0.7070\n",
      "\n",
      "The combination of properties that explains the most variance is:\n",
      "density: 0.7070\n",
      "viscosity: 0.4591\n",
      "specific_heat: 0.5379\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def analyze_fluid_properties(root_dir):\n",
    "    \"\"\"\n",
    "    Analyze fluid properties from a CSV file.\n",
    "\n",
    "    This function reads fluid data from a CSV file, selects the first 5 fluids,\n",
    "    normalizes their properties, calculates the correlation matrix, and performs\n",
    "    eigenvalue decomposition.\n",
    "\n",
    "    Parameters:\n",
    "    root_dir (str): The root directory containing the fluids.csv file.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - normalized_matrix (numpy.ndarray): A 5x3 normalized matrix of fluid properties.\n",
    "        - correlation_matrix (numpy.ndarray): The correlation matrix of the normalized data.\n",
    "        - eigenvalues (numpy.ndarray): The eigenvalues of the correlation matrix.\n",
    "        - eigenvectors (numpy.ndarray): The eigenvectors of the correlation matrix.\n",
    "    \"\"\"\n",
    "    #load data\n",
    "    fluids = pd.read_csv(root_dir + '/fluids.csv')\n",
    "    fluids = fluids[['density', 'viscosity', 'specific_heat']]\n",
    "    fluids = fluids.head(5)\n",
    "    fluids = fluids.to_numpy()\n",
    "\n",
    "    #normalize data\n",
    "    min_values = np.min(fluids, axis=0)\n",
    "    max_values = np.max(fluids, axis=0)\n",
    "\n",
    "    normalized_matrix = (fluids - min_values) / (max_values - min_values)\n",
    "\n",
    "    #calculate correlation matrix \n",
    "    correlation_matrix = np.corrcoef(normalized_matrix, rowvar=False)\n",
    "\n",
    "    #eigenvalue decomposition\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(correlation_matrix)\n",
    "\n",
    "    return normalized_matrix, correlation_matrix, eigenvalues, eigenvectors\n",
    "\n",
    "\n",
    "# Call the function\n",
    "root_dir = 'exercise_data' # change root_dir to where your data for this exercise is\n",
    "normalized_matrix, correlation_matrix, eigenvalues, eigenvectors = analyze_fluid_properties(root_dir)\n",
    "\n",
    "# Print results\n",
    "print(\"Normalized 5x3 Fluid Property Matrix:\")\n",
    "print(normalized_matrix)\n",
    "\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "print(\"\\nEigenvalues:\")\n",
    "print(eigenvalues)\n",
    "\n",
    "print(\"\\nEigenvectors:\")\n",
    "print(eigenvectors)\n",
    "\n",
    "# Interpret the results\n",
    "total_variance = np.sum(eigenvalues)\n",
    "explained_variance_ratio = eigenvalues / total_variance\n",
    "\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "for i, ratio in enumerate(explained_variance_ratio):\n",
    "    print(f\"Principal Component {i+1}: {ratio:.4f}\")\n",
    "\n",
    "# Determine which property or combination explains the most variance\n",
    "properties = ['density', 'viscosity', 'specific_heat']\n",
    "max_component = np.argmax(np.abs(eigenvectors[:, 0]))\n",
    "max_contribution = eigenvectors[max_component, 0]\n",
    "\n",
    "print(f\"\\nThe property that contributes most to the first principal component is: {properties[max_component]}\")\n",
    "print(f\"Its contribution is: {max_contribution:.4f}\")\n",
    "\n",
    "# If the contribution is not overwhelmingly large, print the combination\n",
    "if max_contribution < 0.8:\n",
    "    print(\"\\nThe combination of properties that explains the most variance is:\")\n",
    "    for i, prop in enumerate(properties):\n",
    "        print(f\"{prop}: {eigenvectors[i, 0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two most similar fluids are:\n",
      "1. Oil (ID: 3)\n",
      "2. Propylene Glycol (ID: 9)\n",
      "Cosine similarity: 0.9998\n",
      "\n",
      "Their properties are:\n",
      "Property        Fluid 1         Fluid 2        \n",
      "---------------------------------------------\n",
      "density         850.0000        1030.0000      \n",
      "viscosity       10.0000         60.0000        \n",
      "specific_heat   2000.0000       2500.0000      \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    #Calculate cosine similarity between two vectors\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "def find_most_similar_fluids(root_dir):\n",
    "    \"\"\"\n",
    "    Find the two most similar fluids based on their properties.\n",
    "\n",
    "    This function loads fluid data from a CSV file, computes the cosine similarity between each pair of fluids based on their density, viscosity, and specific heat,  and returns the two most similar fluids along with their similarity score.\n",
    "\n",
    "    Parameters:\n",
    "    root_dir (str): The directory path where the fluids.csv file is located.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing three elements:\n",
    "        - fluid1 (pandas.Series): The first fluid of the most similar pair.\n",
    "        - fluid2 (pandas.Series): The second fluid of the most similar pair.\n",
    "        - max_similarity (float): The cosine similarity between the two most similar fluids.\n",
    "    \"\"\"\n",
    "    # Load fluid data\n",
    "    fluids = pd.read_csv(root_dir + '/fluids.csv')\n",
    "\n",
    "    # Select properties for comparison\n",
    "    properties = ['density', 'viscosity', 'specific_heat']\n",
    "    fluid_properties = fluids[properties].to_numpy()\n",
    "\n",
    "    # Calculate cosine similarity between each pair of fluids\n",
    "    similarities = []\n",
    "    for i in range(len(fluids)):\n",
    "        for j in range(i+1, len(fluids)):\n",
    "            similarity = cosine_similarity(fluid_properties[i], fluid_properties[j])\n",
    "            similarities.append((i, j, similarity))\n",
    "\n",
    "    # Find the two most similar fluids\n",
    "    max_similarity = max(similarities, key=lambda x: x[2])\n",
    "    fluid1 = fluids.iloc[max_similarity[0]]\n",
    "    fluid2 = fluids.iloc[max_similarity[1]]\n",
    "\n",
    "    return fluid1, fluid2, max_similarity[2]\n",
    "\n",
    "# Call the function\n",
    "root_dir = 'exercise_data' # change root_dir to where your data for this exercise is\n",
    "fluid1, fluid2, similarity = find_most_similar_fluids(root_dir)\n",
    "\n",
    "# Print results\n",
    "print(f\"The two most similar fluids are:\")\n",
    "print(f\"1. {fluid1['fluid_name']} (ID: {fluid1['fluid_id']})\")\n",
    "print(f\"2. {fluid2['fluid_name']} (ID: {fluid2['fluid_id']})\")\n",
    "print(f\"Cosine similarity: {similarity:.4f}\")\n",
    "\n",
    "print(\"\\nTheir properties are:\")\n",
    "print(f\"{'Property':<15} {'Fluid 1':<15} {'Fluid 2':<15}\")\n",
    "print(\"-\" * 45)\n",
    "for prop in ['density', 'viscosity', 'specific_heat']:\n",
    "    print(f\"{prop:<15} {fluid1[prop]:<15.4f} {fluid2[prop]:<15.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ME371",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
