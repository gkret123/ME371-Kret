{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 - - NUMPY and PANDAS FOR DATA ANALYSIS\n",
    "# Gabriel Kret\n",
    "# Due: 10/21/2024\n",
    "\n",
    "#This exercise is about using numpy and pandas to analyze data.\n",
    "\n",
    "#Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write 2 specific empty spaces in experiments.csv with explicit values\n",
    "\n",
    "#When experiment_id = 7, fluid_id = 8\n",
    "#When experiment_id = 15, fluid_id = 9\n",
    "\n",
    "#read the csv file\n",
    "df = pd.read_csv('exercise_data/experiments.csv')\n",
    "df.loc[df['experiment_id'] == 7, 'fluid_id'] = int(8)\n",
    "df.loc[df['experiment_id'] == 15, 'fluid_id'] = int(9)\n",
    "df['fluid_id'] = df['fluid_id'].astype('Int64')\n",
    "\n",
    "#write the new csv file\n",
    "df.to_csv('exercise_data/experiments.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[( 1, 'Water', 5.2242642e+03, 5.345930e+03, 2.5031309e+03, 2.49     , 1.99 , 1.8665386, 49.854286, 51.72 , 23.575453 , 1.9514285e+00,  1.56 , 1.4614768e+00)\n",
      " ( 2, 'Air', 7.2733335e+00, 8.050000e+00, 1.6667433e+00, 2.4566667, 1.48 , 2.2130146, 56.45    , 57.61 ,  5.541814 , 3.3333334e-03,  0.   , 5.7735029e-03)\n",
      " ( 3, 'Oil', 2.7786873e+03, 2.798740e+03, 2.0238268e+03, 3.0414286, 3.26 , 1.3726668, 52.025715, 46.17 , 20.646303 , 2.6657143e+00,  2.86 , 1.2028973e+00)\n",
      " ( 6, 'Mercury', 3.0704099e+03, 1.724200e+03, 2.3592539e+03, 3.7733333, 3.49 , 1.0151026, 75.56333 , 89.12 , 33.34987  , 3.0366666e+00,  2.81 , 8.1402296e-01)\n",
      " ( 7, 'Acetone', 6.0995609e+04, 6.099207e+04, 1.5003267e+04, 2.3575   , 2.79 , 1.157076 , 58.9325  , 53.525, 18.587267 , 3.1934999e+01, 37.79 , 1.5672393e+01)\n",
      " ( 8, 'Benzene', 4.7392998e+03, 4.509840e+03, 1.5979779e+03, 2.745    , 2.455, 1.218043 , 47.13375 , 31.215, 32.145294 , 2.3337500e+00,  2.09 , 1.0354977e+00)\n",
      " ( 9, 'Propylene Glycol', 5.0339346e+03, 4.646330e+03, 3.0479341e+03, 2.63375  , 2.395, 1.1393675, 63.770626, 64.3  , 21.54185  , 2.7131250e+00,  2.47 , 1.1726706e+00)\n",
      " (10, 'Liquid Nitrogen', 7.6082651e+03, 7.608265e+03, 3.2917588e+03, 2.255    , 2.255, 1.661701 , 98.105   , 98.105,  2.6657925, 2.2550001e+00,  2.255, 1.6617010e+00)]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def calculate_fluid_statistics(root_dir):\n",
    "    \"\"\"\n",
    "    Calculate statistics for fluid experiments from CSV files.\n",
    "\n",
    "    This function loads data from fluids.csv, experiments.csv, and fluid_measurements.csv, merges the data, and calculates mean, median, and standard deviation of pressure, velocity, temperature, and flow_rate for each unique fluid.\n",
    "\n",
    "    Parameters:\n",
    "    root_dir (str): The root directory containing the CSV files.\n",
    "\n",
    "    Returns:\n",
    "    np.array: A structured NumPy array containing the calculated statistics for each fluid.\n",
    "        The array has the following fields:\n",
    "        - fluid_id (int): The unique identifier for each fluid.\n",
    "        - fluid_name (str): The name of the fluid.\n",
    "        - pressure_mean, pressure_median, pressure_std (float): Statistics for pressure.\n",
    "        - velocity_mean, velocity_median, velocity_std (float): Statistics for velocity.\n",
    "        - temperature_mean, temperature_median, temperature_std (float): Statistics for temperature.\n",
    "        - flow_rate_mean, flow_rate_median, flow_rate_std (float): Statistics for flow rate.\n",
    "    \"\"\"\n",
    "    #read data\n",
    "    fluids = pd.read_csv(root_dir + '/fluids.csv')\n",
    "    experiments = pd.read_csv(root_dir + '/experiments.csv')\n",
    "    fluid_measurements = pd.read_csv(root_dir + '/fluid_measurements.csv')\n",
    "    \n",
    "    #merge data\n",
    "    data = pd.merge(fluid_measurements, experiments, on='experiment_id', how='left')\n",
    "    data = pd.merge(data, fluids, on='fluid_id', how = 'left')\n",
    "\n",
    "    #calculate statistics\n",
    "    stats = data.groupby('fluid_name').agg({\n",
    "        'pressure': ['mean', 'median', 'std'],\n",
    "        'velocity': ['mean', 'median', 'std'],\n",
    "        'temperature': ['mean', 'median', 'std'],\n",
    "        'flow_rate': ['mean', 'median', 'std'],\n",
    "    })\n",
    "\n",
    "    #create array\n",
    "    result_array = np.array(np.zeros(len(stats)), dtype=[('fluid_id', 'i4'), ('fluid_name', 'U50'), ('pressure_mean', 'f4'), ('pressure_median', 'f4'), ('pressure_std', 'f4'), ('velocity_mean', 'f4'), ('velocity_median', 'f4'), ('velocity_std', 'f4'), ('temperature_mean', 'f4'), ('temperature_median', 'f4'), ('temperature_std', 'f4'), ('flow_rate_mean', 'f4'), ('flow_rate_median', 'f4'), ('flow_rate_std', 'f4')])\n",
    "    result_array['fluid_id'] = data.groupby('fluid_id')['fluid_id'].first().values\n",
    "    result_array['fluid_name'] = data.groupby('fluid_id')['fluid_name'].first().values\n",
    "    result_array['pressure_mean'] = stats['pressure']['mean'].values\n",
    "    result_array['pressure_median'] = stats['pressure']['median'].values\n",
    "    result_array['pressure_std'] = stats['pressure']['std'].values\n",
    "    result_array['velocity_mean'] = stats['velocity']['mean'].values\n",
    "    result_array['velocity_median'] = stats['velocity']['median'].values\n",
    "    result_array['velocity_std'] = stats['velocity']['std'].values\n",
    "    result_array['temperature_mean'] = stats['temperature']['mean'].values\n",
    "    result_array['temperature_median'] = stats['temperature']['median'].values\n",
    "    result_array['temperature_std'] = stats['temperature']['std'].values\n",
    "    result_array['flow_rate_mean'] = stats['flow_rate']['mean'].values\n",
    "    result_array['flow_rate_median'] = stats['flow_rate']['median'].values\n",
    "    result_array['flow_rate_std'] = stats['flow_rate']['std'].values\n",
    "\n",
    "    print(result_array)\n",
    "      \n",
    "\n",
    "# Call the function and print the results\n",
    "result_array = calculate_fluid_statistics(root_dir='exercise_data') # change root_dir to where your data for this exercise is\n",
    "print(result_array)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment IDs for fluid_id 1:\n",
      "[13  8]\n",
      "\n",
      "Correlation Matrix:\n",
      "             pressure  velocity  temperature  flow_rate\n",
      "pressure          1.0       1.0         -1.0        1.0\n",
      "velocity          1.0       1.0         -1.0        1.0\n",
      "temperature      -1.0      -1.0          1.0       -1.0\n",
      "flow_rate         1.0       1.0         -1.0        1.0\n"
     ]
    }
   ],
   "source": [
    "def get_experiments_and_correlation(root_dir, fluid_id):\n",
    "    \"\"\"\n",
    "    Retrieves experiment IDs for a given fluid and calculates the correlation matrix of measurements.\n",
    "\n",
    "    Parameters:\n",
    "    root_dir (str): The root directory containing the CSV files.\n",
    "    fluid_id (int): The ID of the fluid to analyze.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two elements:\n",
    "        - numpy.ndarray: An array of experiment IDs associated with the given fluid_id.\n",
    "        - pandas.DataFrame: A correlation matrix of pressure, velocity, temperature, and flow_rate for the experiments associated with the given fluid_id.\n",
    "    \"\"\"\n",
    "    #read data\n",
    "    fluids = pd.read_csv(root_dir + '/fluids.csv')\n",
    "    experiments = pd.read_csv(root_dir + '/experiments.csv')\n",
    "    fluid_measurements = pd.read_csv(root_dir + '/fluid_measurements.csv')\n",
    "\n",
    "    #merge data\n",
    "    data = pd.merge(fluid_measurements, experiments, on='experiment_id', how='left')\n",
    "    data = pd.merge(data, fluids, on='fluid_id', how = 'left')\n",
    "\n",
    "    #get experiment ids\n",
    "    experiment_ids = data[data['fluid_id'] == fluid_id]['experiment_id'].values\n",
    "\n",
    "    #calculate correlation matrix\n",
    "    correlation_matrix = data[data['fluid_id'] == fluid_id][['pressure', 'velocity', 'temperature', 'flow_rate']].corr()\n",
    "\n",
    "    return np.array(experiment_ids), correlation_matrix\n",
    "    \n",
    "\n",
    "# Call the function\n",
    "root_dir = 'exercise_data' # change root_dir to where your data for this exercise is\n",
    "fluid_id = 1\n",
    "experiment_ids, correlation_matrix = get_experiments_and_correlation(root_dir, fluid_id)\n",
    "\n",
    "# Print results\n",
    "print(f\"Experiment IDs for fluid_id {fluid_id}:\")\n",
    "print(experiment_ids)\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized 5x3 Fluid Property Matrix:\n",
      "[[7.93449981e-01 6.54607899e-04 1.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.74286509e-01 6.65468030e-03 3.12991507e-01]\n",
      " [6.25826697e-01 7.87942841e-04 4.38817238e-01]\n",
      " [1.00000000e+00 1.00000000e+00 4.38817238e-01]]\n",
      "\n",
      "Normalized Matrix with Column Names:\n",
      "    density  viscosity  specific_heat\n",
      "0  0.793450   0.000655       1.000000\n",
      "1  0.000000   0.000000       0.000000\n",
      "2  0.674287   0.006655       0.312992\n",
      "3  0.625827   0.000788       0.438817\n",
      "4  1.000000   1.000000       0.438817\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_normalized_fluid_matrix(root_dir):\n",
    "    \"\"\"\n",
    "    Create a normalized 5x3 matrix of fluid properties.\n",
    "\n",
    "    This function reads fluid data from a CSV file, selects the first 5 fluids, and creates a matrix of their density, viscosity, and specific heat properties. The matrix is then normalized using min-max normalization.\n",
    "\n",
    "    Parameters:\n",
    "    root_dir (str): The root directory containing the fluids.csv file.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 5x3 normalized matrix where each row represents a fluid and each column represents a normalized property (density, viscosity, specific_heat).\n",
    "    \"\"\"\n",
    "    fluids = pd.read_csv(root_dir + '/fluids.csv')\n",
    "    fluids = fluids[['density', 'viscosity', 'specific_heat']]\n",
    "    fluids = fluids.head(5)\n",
    "    fluids = fluids.to_numpy()\n",
    "\n",
    "    min_values = np.min(fluids, axis=0)\n",
    "    max_values = np.max(fluids, axis=0)\n",
    "\n",
    "    normalized_fluids = (fluids - min_values) / (max_values - min_values)\n",
    "\n",
    "    return normalized_fluids\n",
    "\n",
    "# Call the function\n",
    "root_dir = 'exercise_data' # change root_dir to where your data for this exercise is\n",
    "result_matrix = create_normalized_fluid_matrix(root_dir)\n",
    "\n",
    "# Print the result\n",
    "print(\"Normalized 5x3 Fluid Property Matrix:\")\n",
    "print(result_matrix)\n",
    "\n",
    "# Print with column names for clarity\n",
    "column_names = ['density', 'viscosity', 'specific_heat']\n",
    "result_df = pd.DataFrame(result_matrix, columns=column_names)\n",
    "print(\"\\nNormalized Matrix with Column Names:\")\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized 5x3 Fluid Property Matrix:\n",
      "[[7.93449981e-01 6.54607899e-04 1.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.74286509e-01 6.65468030e-03 3.12991507e-01]\n",
      " [6.25826697e-01 7.87942841e-04 4.38817238e-01]\n",
      " [1.00000000e+00 1.00000000e+00 4.38817238e-01]]\n",
      "\n",
      "Correlation Matrix:\n",
      "[[1.00000000e+00 5.70589790e-01 6.68644167e-01]\n",
      " [5.70589790e-01 1.00000000e+00 3.52574102e-04]\n",
      " [6.68644167e-01 3.52574102e-04 1.00000000e+00]]\n",
      "\n",
      "Eigenvalues:\n",
      "[1.87918363 0.12116456 0.99965181]\n",
      "\n",
      "Eigenvectors:\n",
      "[[ 7.07036753e-01  7.07176800e-01  6.30797704e-05]\n",
      " [ 4.59082256e-01 -4.58923489e-01 -7.60679114e-01]\n",
      " [ 5.37905672e-01 -5.37857049e-01  6.49128094e-01]]\n",
      "\n",
      "Explained Variance Ratio:\n",
      "Principal Component 1: 0.6264\n",
      "Principal Component 2: 0.0404\n",
      "Principal Component 3: 0.3332\n",
      "\n",
      "The property that contributes most to the first principal component is: density\n",
      "Its contribution is: 0.7070\n",
      "\n",
      "The combination of properties that explains the most variance is:\n",
      "density: 0.7070\n",
      "viscosity: 0.4591\n",
      "specific_heat: 0.5379\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def analyze_fluid_properties(root_dir):\n",
    "    \"\"\"\n",
    "    Analyze fluid properties from a CSV file.\n",
    "\n",
    "    This function reads fluid data from a CSV file, selects the first 5 fluids,\n",
    "    normalizes their properties, calculates the correlation matrix, and performs\n",
    "    eigenvalue decomposition.\n",
    "\n",
    "    Parameters:\n",
    "    root_dir (str): The root directory containing the fluids.csv file.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - normalized_matrix (numpy.ndarray): A 5x3 normalized matrix of fluid properties.\n",
    "        - correlation_matrix (numpy.ndarray): The correlation matrix of the normalized data.\n",
    "        - eigenvalues (numpy.ndarray): The eigenvalues of the correlation matrix.\n",
    "        - eigenvectors (numpy.ndarray): The eigenvectors of the correlation matrix.\n",
    "    \"\"\"\n",
    "    #load data\n",
    "    fluids = pd.read_csv(root_dir + '/fluids.csv')\n",
    "    fluids = fluids[['density', 'viscosity', 'specific_heat']]\n",
    "    fluids = fluids.head(5)\n",
    "    fluids = fluids.to_numpy()\n",
    "\n",
    "    #normalize data\n",
    "    min_values = np.min(fluids, axis=0)\n",
    "    max_values = np.max(fluids, axis=0)\n",
    "\n",
    "    normalized_matrix = (fluids - min_values) / (max_values - min_values)\n",
    "\n",
    "    #calculate correlation matrix \n",
    "    correlation_matrix = np.corrcoef(normalized_matrix, rowvar=False)\n",
    "\n",
    "    #eigenvalue decomposition\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(correlation_matrix)\n",
    "\n",
    "    return normalized_matrix, correlation_matrix, eigenvalues, eigenvectors\n",
    "\n",
    "\n",
    "# Call the function\n",
    "root_dir = 'exercise_data' # change root_dir to where your data for this exercise is\n",
    "normalized_matrix, correlation_matrix, eigenvalues, eigenvectors = analyze_fluid_properties(root_dir)\n",
    "\n",
    "# Print results\n",
    "print(\"Normalized 5x3 Fluid Property Matrix:\")\n",
    "print(normalized_matrix)\n",
    "\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "print(\"\\nEigenvalues:\")\n",
    "print(eigenvalues)\n",
    "\n",
    "print(\"\\nEigenvectors:\")\n",
    "print(eigenvectors)\n",
    "\n",
    "# Interpret the results\n",
    "total_variance = np.sum(eigenvalues)\n",
    "explained_variance_ratio = eigenvalues / total_variance\n",
    "\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "for i, ratio in enumerate(explained_variance_ratio):\n",
    "    print(f\"Principal Component {i+1}: {ratio:.4f}\")\n",
    "\n",
    "# Determine which property or combination explains the most variance\n",
    "properties = ['density', 'viscosity', 'specific_heat']\n",
    "max_component = np.argmax(np.abs(eigenvectors[:, 0]))\n",
    "max_contribution = eigenvectors[max_component, 0]\n",
    "\n",
    "print(f\"\\nThe property that contributes most to the first principal component is: {properties[max_component]}\")\n",
    "print(f\"Its contribution is: {max_contribution:.4f}\")\n",
    "\n",
    "# If the contribution is not overwhelmingly large, print the combination\n",
    "if max_contribution < 0.8:\n",
    "    print(\"\\nThe combination of properties that explains the most variance is:\")\n",
    "    for i, prop in enumerate(properties):\n",
    "        print(f\"{prop}: {eigenvectors[i, 0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two most similar fluids are:\n",
      "1. Oil (ID: 3)\n",
      "2. Propylene Glycol (ID: 9)\n",
      "Cosine similarity: 0.9998\n",
      "\n",
      "Their properties are:\n",
      "Property Fluid 1 Fluid 2\n",
      "density 850.0 1030.0\n",
      "viscosity 10.0 60.0\n",
      "specific_heat 2000 2500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    #Calculate cosine similarity between two vectors\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "def find_most_similar_fluids(root_dir):\n",
    "    \"\"\"\n",
    "    Find the two most similar fluids based on their properties.\n",
    "\n",
    "    This function loads fluid data from a CSV file, computes the cosine similarity between each pair of fluids based on their density, viscosity, and specific heat,  and returns the two most similar fluids along with their similarity score.\n",
    "\n",
    "    Parameters:\n",
    "    root_dir (str): The directory path where the fluids.csv file is located.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing three elements:\n",
    "        - fluid1 (pandas.Series): The first fluid of the most similar pair.\n",
    "        - fluid2 (pandas.Series): The second fluid of the most similar pair.\n",
    "        - max_similarity (float): The cosine similarity between the two most similar fluids.\n",
    "    \"\"\"\n",
    "    # Load fluid data\n",
    "    fluids = pd.read_csv(root_dir + '/fluids.csv')\n",
    "\n",
    "    # Select properties for comparison\n",
    "    properties = ['density', 'viscosity', 'specific_heat']\n",
    "    fluid_properties = fluids[properties].to_numpy()\n",
    "\n",
    "    # Calculate cosine similarity between each pair of fluids\n",
    "    similarities = []\n",
    "    for i in range(len(fluids)):\n",
    "        for j in range(i+1, len(fluids)):\n",
    "            similarity = cosine_similarity(fluid_properties[i], fluid_properties[j])\n",
    "            similarities.append((i, j, similarity))\n",
    "\n",
    "    # Find the two most similar fluids\n",
    "    max_similarity = max(similarities, key=lambda x: x[2])\n",
    "    fluid1 = fluids.iloc[max_similarity[0]]\n",
    "    fluid2 = fluids.iloc[max_similarity[1]]\n",
    "\n",
    "    return fluid1, fluid2, max_similarity[2]\n",
    "\n",
    "# Call the function\n",
    "root_dir = 'exercise_data' # change root_dir to where your data for this exercise is\n",
    "fluid1, fluid2, similarity = find_most_similar_fluids(root_dir)\n",
    "\n",
    "# Print results\n",
    "print(f\"The two most similar fluids are:\")\n",
    "print(f\"1. {fluid1['fluid_name']} (ID: {fluid1['fluid_id']})\")\n",
    "print(f\"2. {fluid2['fluid_name']} (ID: {fluid2['fluid_id']})\")\n",
    "print(f\"Cosine similarity: {similarity:.4f}\")\n",
    "\n",
    "print(\"\\nTheir properties are:\")\n",
    "print(f\"{'Property'} {'Fluid 1'} {'Fluid 2'}\")\n",
    "for prop in ['density', 'viscosity', 'specific_heat']:\n",
    "    print(f\"{prop} {fluid1[prop]} {fluid2[prop]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in systems: 0\n",
      "Missing values in sensors: 0\n",
      "Missing values in control_actions: 0\n",
      "Missing values in measurements: 0\n",
      "Missing values in signal_data: 0\n",
      "Missing values in signal_char: 0\n",
      "Data types in systems:\n",
      " system_id       int64\n",
      "system_name    object\n",
      "system_type    object\n",
      "description    object\n",
      "dtype: object\n",
      "Data types in sensors: \n",
      " sensor_id       int64\n",
      "sensor_name    object\n",
      "sensor_type    object\n",
      "unit           object\n",
      "system_id       int64\n",
      "dtype: object\n",
      "Data types in control_actions: \n",
      " action_id                int64\n",
      "system_id                int64\n",
      "action_type             object\n",
      "action_value           float64\n",
      "timestamp       datetime64[ns]\n",
      "dtype: object\n",
      "Data types in measurements: \n",
      " measurement_id             int64\n",
      "sensor_id                  int64\n",
      "timestamp         datetime64[ns]\n",
      "value                    float64\n",
      "dtype: object\n",
      "Data types in signal_data: \n",
      " signal_id             int64\n",
      "sensor_id             int64\n",
      "timestamp    datetime64[ns]\n",
      "value               float64\n",
      "dtype: object\n",
      "Data types in signal_char: \n",
      " characteristic_id      int64\n",
      "sensor_id              int64\n",
      "frequency            float64\n",
      "amplitude            float64\n",
      "signal_type           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Read CSVs\n",
    "systems = pd.read_csv('exercise_data/systems.csv')\n",
    "sensors = pd.read_csv('exercise_data/sensors.csv')\n",
    "control_actions = pd.read_csv('exercise_data/control_actions.csv')\n",
    "measurements = pd.read_csv('exercise_data/measurements.csv')\n",
    "signal_data = pd.read_csv('exercise_data/signal_data.csv')\n",
    "signal_char = pd.read_csv('exercise_data/signal_characteristics.csv')\n",
    "\n",
    "# clean data via interpolation, filling explicitly, or domain knowledge\n",
    "\n",
    "systems['system_id'] = systems['system_id'].interpolate(method='linear').astype(int)\n",
    "systems['system_name'] = systems['system_name'].fillna(systems['system_id'].apply(lambda x: f\"Advanced Control System {x}\"))\n",
    "\n",
    "#count missing values\n",
    "missing_values_systems = systems.isnull().sum().sum()\n",
    "missing_values_sensor = sensors.isnull().sum().sum()\n",
    "missing_values_control_actions = control_actions.isnull().sum().sum()\n",
    "missing_values_measurements = measurements.isnull().sum().sum()\n",
    "missing_values_signal_data = signal_data.isnull().sum().sum()\n",
    "missing_values_signal_char = signal_char.isnull().sum().sum()\n",
    "print(f\"Missing values in systems: {missing_values_systems}\")\n",
    "print(f\"Missing values in sensors: {missing_values_sensor}\")\n",
    "print(f\"Missing values in control_actions: {missing_values_control_actions}\")\n",
    "print(f\"Missing values in measurements: {missing_values_measurements}\")\n",
    "print(f\"Missing values in signal_data: {missing_values_signal_data}\")\n",
    "print(f\"Missing values in signal_char: {missing_values_signal_char}\")\n",
    "\n",
    "\n",
    "\n",
    "#edit date types\n",
    "control_actions['timestamp'] = pd.to_datetime(control_actions['timestamp'])\n",
    "measurements['timestamp'] = pd.to_datetime(measurements['timestamp'])\n",
    "signal_data['timestamp'] = pd.to_datetime(signal_data['timestamp'])\n",
    "\n",
    "\n",
    "\n",
    "#check datatypes\n",
    "print(f\"Data types in systems:\\n {systems.dtypes}\")\n",
    "print(f\"Data types in sensors: \\n {sensors.dtypes}\")\n",
    "print(f\"Data types in control_actions: \\n {control_actions.dtypes}\")\n",
    "print(f\"Data types in measurements: \\n {measurements.dtypes}\")\n",
    "print(f\"Data types in signal_data: \\n {signal_data.dtypes}\")\n",
    "print(f\"Data types in signal_char: \\n {signal_char.dtypes}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ME371",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
